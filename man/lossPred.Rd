% Generated by roxygen2 (4.0.1): do not edit by hand
\name{lossPred}
\alias{lossPred}
\title{Instantaneous loss suffered by a prediction}
\usage{
lossPred(x, y, pred = NULL, loss.type = "squareloss",
  loss.gradient = FALSE, tau = 0.1)
}
\arguments{
\item{x}{A vector of \code{N} prediction of
the observation \code{y} to be evaluated.}

\item{y}{A number containing the observation.}

\item{pred}{A reference prediction that the
predictions in \code{x} aim to correct.}

\item{loss.type}{A string specifying
the loss function considered to evaluate the performance. It can be
"squareloss", "mae", "mape", or "pinballloss". See \code{\link{loss}} for
more details.}

\item{loss.gradient}{A boolean. If
TRUE (default) the aggregation rule will not be directly applied to the loss
function at hand but to a gradient version of it. The aggregation rule is
then similar to gradient descent aggregation rule.}

\item{tau}{A number in \code{[0,1]}
describing the quantile to be predicted. Used only if \code{loss.type =
"pinballloss"}.}
}
\value{
A vector containing the loss suffered by the \code{N}
predictions in \code{x}.
}
\description{
The
function \code{lossPred} computes the loss of a prediction \code{x} of an
obstervation \code{y} knowing that we want to correct the error commited by
the prediction \code{pred}.  It is used in the mixing aggregation rule (see
\code{\link{mixture}}) to compute the loss of the experts at each
instance.  We can choose \code{pred} to be the prediction of \code{y}
outputed by the aggregation rule.
}
\author{
Pierre Gaillard <pierre-p.gaillard@edf.fr>
}
\seealso{
\code{\link{loss}}
}
\keyword{~kwd1}
\keyword{~kwd2}

